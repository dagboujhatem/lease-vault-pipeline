# üîÑ Rollback et R√©cup√©ration apr√®s Suppression par Erreur

## ‚ö†Ô∏è Limitations Importantes

**IMPORTANT : Vault ne permet PAS de restaurer directement un lease supprim√©.**

Une fois qu'un lease est r√©voqu√©/d√©truit via l'API Vault :
- Le lease est **imm√©diatement et d√©finitivement supprim√©**
- Les secrets associ√©s sont **invalid√©s imm√©diatement**
- **Aucune restauration automatique n'est possible**

## Strat√©gies de Pr√©vention (AVANT la Destruction)

### 1. Sauvegarder le Fichier JSON Avant Destruction

**CRITIQUE** : Toujours sauvegarder le fichier `leases.json` avant de d√©truire des leases.

```bash
# Avant d'ex√©cuter la destruction, sauvegarder le fichier
cp leases.json leases.json.backup-$(date +%Y%m%d-%H%M%S)

# Ou dans GitLab CI, cr√©er un artifact sauvegard√©
# Le fichier JSON est d√©j√† un artifact, mais sauvegardez-le ailleurs aussi
```

### 2. Utiliser DESTROY_ORPHANS_ONLY=true

**Recommandation FORTE** : Toujours utiliser `DESTROY_ORPHANS_ONLY=true` sauf cas exceptionnel.

```yaml
variables:
  DESTROY_ORPHANS_ONLY: "true"  # Ne d√©truire QUE les orphelins
```

### 3. Utiliser la Destruction Manuelle

Dans `gitlab-ci.yaml`, la destruction est configur√©e comme manuelle :
```yaml
destroy_vault_leases:
  when: manual  # N√©cessite une confirmation manuelle
```

### 4. Sauvegarde Automatique dans la Pipeline

**Recommandation** : Modifier le script `destroy-lease.sh` pour cr√©er automatiquement une sauvegarde avant destruction.

## Proc√©dures de R√©cup√©ration (APR√àS une Suppression par Erreur)

Si des leases ont √©t√© supprim√©s par erreur, voici les proc√©dures de r√©cup√©ration :

### √âtape 1 : √âvaluer l'Impact

```bash
# V√©rifier quels pods sont affect√©s
kubectl get pods -n <namespace> --field-selector=status.phase!=Running

# V√©rifier les erreurs dans les logs
kubectl logs -n <namespace> <pod-name> | grep -i "vault\|secret\|credential\|auth"

# V√©rifier les √©v√©nements Kubernetes
kubectl get events -n <namespace> --sort-by='.lastTimestamp'

# V√©rifier le statut des deployments
kubectl get deployments -n <namespace>

# V√©rifier les statefulsets
kubectl get statefulsets -n <namespace>
```

### √âtape 2 : Identifier les Secrets Perdus

Si vous avez sauvegard√© le fichier `leases.json`, vous pouvez identifier ce qui a √©t√© supprim√© :

```bash
# Lister tous les leases qui ont √©t√© d√©truits (si vous avez le backup)
cat leases.json.backup-YYYYMMDD-HHMMSS | jq '.[] | {
  path: .path,
  lease_id: .lease_id,
  full_path: .full_path,
  ttl: .ttl,
  renewable: .renewable,
  orphan: .orphan
}'

# Compter le nombre de leases d√©truits
cat leases.json.backup-YYYYMMDD-HHMMSS | jq '. | length'

# Lister uniquement les leases orphelins qui ont √©t√© d√©truits
cat leases.json.backup-YYYYMMDD-HHMMSS | jq '[.[] | select(.orphan == true)]'
```

### √âtape 3 : Red√©marrer les Pods pour R√©g√©n√©rer les Secrets

Les secrets dynamiques Vault sont r√©g√©n√©r√©s automatiquement lorsque les pods sont red√©marr√©s. Voici plusieurs m√©thodes :

#### M√©thode 1 : Red√©ploiement des Deployments

```bash
# Forcer le red√©ploiement de tous les deployments du namespace
kubectl rollout restart deployment -n <namespace>

# Attendre que les pods soient red√©marr√©s
kubectl rollout status deployment -n <namespace> --timeout=300s

# V√©rifier le statut de chaque deployment
for deployment in $(kubectl get deployments -n <namespace> -o name); do
    echo "V√©rification: $deployment"
    kubectl rollout status $deployment -n <namespace>
done
```

#### M√©thode 2 : Suppression et Recr√©ation des Pods

```bash
# Supprimer tous les pods (ils seront recr√©√©s automatiquement par les controllers)
kubectl delete pods -n <namespace> --all

# V√©rifier que les nouveaux pods d√©marrent correctement
kubectl get pods -n <namespace> -w

# Surveiller les pods jusqu'√† ce qu'ils soient tous Running
watch kubectl get pods -n <namespace>
```

#### M√©thode 3 : Red√©marrage via Scale Down/Up

```bash
# Scale down √† 0 replicas pour tous les deployments
for deployment in $(kubectl get deployments -n <namespace> -o name); do
    echo "Scale down: $deployment"
    kubectl scale $deployment --replicas=0 -n <namespace>
done

# Attendre quelques secondes
sleep 10

# Scale up √† nouveau avec le nombre original de replicas
# (√Ä adapter selon vos besoins)
for deployment in $(kubectl get deployments -n <namespace> -o name); do
    # R√©cup√©rer le nombre original de replicas depuis un backup ou config
    replicas=2  # Adapter selon votre configuration
    echo "Scale up: $deployment √† $replicas replicas"
    kubectl scale $deployment --replicas=$replicas -n <namespace>
done
```

#### M√©thode 4 : Red√©marrer les StatefulSets

```bash
# Pour les StatefulSets, il faut red√©marrer chaque pod individuellement
# (les StatefulSets maintiennent un ordre sp√©cifique)

# M√©thode 1: Supprimer les pods un par un (ils seront recr√©√©s dans l'ordre)
kubectl delete pods -n <namespace> -l app=<app-label>

# M√©thode 2: Utiliser kubectl rollout restart (si support√©)
kubectl rollout restart statefulset <statefulset-name> -n <namespace>
```

### √âtape 4 : V√©rifier que Vault G√©n√®re de Nouveaux Leases

Apr√®s le red√©marrage des pods :

```bash
# Lister les nouveaux leases g√©n√©r√©s
export VAULT_ADDR="https://vault-hprod.example.com:8200"  # ou vault-prod
export VAULT_TOKEN="${VAULT_TOKEN}"

# Utiliser cette pipeline pour lister les nouveaux leases
# Les pods red√©marr√©s devraient avoir cr√©√© de nouveaux leases
export LEASE_LIST_PATHS="<path-du-namespace>"
# Ex√©cuter: stage list_leases

# V√©rifier que les nouveaux leases sont pr√©sents
cat leases.json | jq '.[] | select(.path == "<path>") | {
  full_path: .full_path,
  issue_time: .issue_time,
  ttl: .ttl,
  orphan: .orphan
}'

# Compter les nouveaux leases g√©n√©r√©s
cat leases.json | jq '. | length'

# Comparer avec le backup (si disponible)
echo "Leases avant destruction: $(cat leases.json.backup-YYYYMMDD-HHMMSS | jq '. | length')"
echo "Leases apr√®s r√©cup√©ration: $(cat leases.json | jq '. | length')"
```

### √âtape 5 : V√©rifier le Fonctionnement des Applications

```bash
# V√©rifier que les pods d√©marrent correctement
kubectl get pods -n <namespace>

# V√©rifier que tous les pods sont en √©tat Running
kubectl get pods -n <namespace> | grep -v Running && echo "‚ö†Ô∏è Certains pods ne sont pas Running" || echo "‚úì Tous les pods sont Running"

# V√©rifier les logs pour confirmer que les secrets sont accessibles
for pod in $(kubectl get pods -n <namespace> -o name); do
    echo "=== Logs de $pod ==="
    kubectl logs $pod -n <namespace> --tail=20 | grep -i "vault\|secret\|credential\|auth\|error" || echo "Aucune erreur li√©e √† Vault d√©tect√©e"
    echo ""
done

# V√©rifier les health checks des applications
kubectl get pods -n <namespace> -o json | jq '.items[] | {
  name: .metadata.name,
  phase: .status.phase,
  ready: .status.conditions[] | select(.type=="Ready") | .status
}'

# Tester une fonctionnalit√© critique de l'application
# (par exemple, acc√®s √† une base de donn√©es, API externe, etc.)
kubectl exec -n <namespace> <pod-name> -- curl -s http://localhost:8080/health || echo "‚ö†Ô∏è Health check √©chou√©"
```

## R√©cup√©ration pour les Pipelines CI/CD

Si des pipelines ont √©t√© interrompues :

### 1. V√©rifier l'√âtat des Pipelines

```bash
# Dans GitLab, v√©rifier les pipelines en √©chec
# GitLab UI > CI/CD > Pipelines

# Via API GitLab
GITLAB_TOKEN="your-token"
GITLAB_URL="https://gitlab.example.com"
PROJECT_ID="123"

# Lister les pipelines r√©centes
curl -s --header "PRIVATE-TOKEN: $GITLAB_TOKEN" \
  "$GITLAB_URL/api/v4/projects/$PROJECT_ID/pipelines?status=failed&per_page=10" | \
  jq '.[] | {id, status, ref, created_at}'
```

### 2. Identifier les Jobs en √âchec

```bash
# Pour chaque pipeline en √©chec, identifier les jobs affect√©s
PIPELINE_ID="456"

curl -s --header "PRIVATE-TOKEN: $GITLAB_TOKEN" \
  "$GITLAB_URL/api/v4/projects/$PROJECT_ID/pipelines/$PIPELINE_ID/jobs" | \
  jq '.[] | select(.status=="failed") | {id, name, stage, status, failure_reason}'
```

### 3. Relancer les Pipelines

#### Via GitLab UI
1. Aller dans CI/CD > Pipelines
2. Identifier les pipelines qui ont √©chou√©
3. Cliquer sur "Retry" pour relancer

#### Via GitLab API

```bash
# Relancer une pipeline sp√©cifique
PIPELINE_ID="456"

curl -X POST \
  --header "PRIVATE-TOKEN: $GITLAB_TOKEN" \
  "$GITLAB_URL/api/v4/projects/$PROJECT_ID/pipelines/$PIPELINE_ID/retry"

# Relancer un job sp√©cifique
JOB_ID="789"

curl -X POST \
  --header "PRIVATE-TOKEN: $GITLAB_TOKEN" \
  "$GITLAB_URL/api/v4/projects/$PROJECT_ID/jobs/$JOB_ID/retry"
```

### 4. V√©rifier que les Nouveaux Secrets sont G√©n√©r√©s

```bash
# Les pipelines IAC/CD g√©n√®rent normalement leurs propres secrets
# V√©rifier que les nouveaux leases sont cr√©√©s lors de l'ex√©cution

# Apr√®s relance de la pipeline, lister les nouveaux leases
export LEASE_LIST_PATHS="<path-utilis√©-par-la-pipeline>"
./scripts/list-lease.sh

# V√©rifier que de nouveaux leases apparaissent
cat leases.json | jq '.[] | select(.issue_time > "<timestamp-de-la-destruction>")'
```

## Cas Particuliers : Secrets Statiques vs Dynamiques

### Secrets Dynamiques (AWS, Database, etc.)

**Cas le plus courant** : Les secrets sont r√©g√©n√©r√©s automatiquement lors de la demande.

#### Secrets AWS (`aws/creds/role`)

```bash
# Un nouveau lease sera cr√©√© automatiquement lors de la prochaine demande
# Les pods red√©marr√©s obtiendront automatiquement de nouveaux credentials AWS

# V√©rifier que les nouveaux credentials sont g√©n√©r√©s
export LEASE_LIST_PATHS="aws/creds/<role>"
./scripts/list-lease.sh

cat leases.json | jq '.[] | {
  lease_id: .lease_id,
  issue_time: .issue_time,
  ttl: .ttl
}'
```

#### Secrets de Base de Donn√©es (`database/creds/role`)

```bash
# Un nouveau mot de passe sera g√©n√©r√© automatiquement
# Les applications red√©marr√©es obtiendront automatiquement de nouveaux mots de passe

# ‚ö†Ô∏è IMPORTANT : Les anciens mots de passe sont invalid√©s
# Assurez-vous que les applications peuvent se reconnecter avec les nouveaux credentials

# V√©rifier que les nouveaux secrets de DB sont g√©n√©r√©s
export LEASE_LIST_PATHS="database/creds/<role>"
./scripts/list-lease.sh
```

**Action** : Red√©marrer les pods suffit g√©n√©ralement, ils r√©g√©n√©reront automatiquement les secrets.

### Secrets Statiques ou Secrets Personnalis√©s

Si des secrets statiques ont √©t√© perdus :

```bash
# 1. V√©rifier si le secret existe toujours dans Vault
vault kv get secret/data/<path>

# 2. Si le secret existe toujours dans Vault (seul le lease a √©t√© d√©truit)
# Les pods peuvent le relire directement apr√®s red√©marrage

# 3. Si le secret lui-m√™me n'existe plus, il faut le recr√©er manuellement
vault kv put secret/data/<path> key1=value1 key2=value2

# 4. Pour les secrets K/V v2
vault kv put secret/<path> key1=value1 key2=value2

# 5. Apr√®s recr√©ation, red√©marrer les pods pour qu'ils puissent lire les secrets
kubectl rollout restart deployment -n <namespace>
```

### Secrets Vault Injector (Kubernetes Sidecar)

Si vous utilisez Vault Injector dans Kubernetes :

```bash
# 1. V√©rifier les annotations Vault sur les pods
kubectl get pod <pod-name> -n <namespace> -o jsonpath='{.metadata.annotations}' | jq '.'

# 2. V√©rifier les sidecars Vault inject√©s
kubectl get pod <pod-name> -n <namespace> -o jsonpath='{.spec.containers[*].name}' | tr ' ' '\n'

# 3. V√©rifier les logs du sidecar Vault
kubectl logs <pod-name> -n <namespace> -c vault-agent

# 4. Si les secrets sont inject√©s via annotations, red√©marrer les pods devrait r√©g√©n√©rer les secrets
kubectl delete pod <pod-name> -n <namespace>

# 5. Le nouveau pod cr√©√© obtiendra automatiquement de nouveaux secrets via Vault Injector
```

## Script d'Aide √† la R√©cup√©ration

Voici un script utile pour faciliter la r√©cup√©ration :

```bash
#!/bin/bash
# Script de r√©cup√©ration apr√®s suppression accidentelle de leases
# Usage: ./scripts/recover-leases.sh <namespace> [backup-file]

set -e

NAMESPACE="${1:-}"
VAULT_ADDR="${VAULT_ADDR:-http://127.0.0.1:8200}"
BACKUP_FILE="${2:-leases.json.backup}"

if [ -z "$NAMESPACE" ]; then
    echo "Usage: $0 <namespace> [backup-file]"
    echo ""
    echo "Exemple:"
    echo "  $0 my-app-prod leases.json.backup-20240101-120000"
    exit 1
fi

echo "=========================================="
echo "Proc√©dure de R√©cup√©ration pour namespace: $NAMESPACE"
echo "=========================================="
echo ""

# 1. √âvaluer l'impact
echo "1. √âvaluation de l'impact..."
pod_count=$(kubectl get pods -n "$NAMESPACE" --no-headers 2>/dev/null | wc -l | tr -d ' ')
echo "  Pods dans le namespace: $pod_count"

deployment_count=$(kubectl get deployments -n "$NAMESPACE" --no-headers 2>/dev/null | wc -l | tr -d ' ')
echo "  Deployments dans le namespace: $deployment_count"

failed_pods=$(kubectl get pods -n "$NAMESPACE" --field-selector=status.phase!=Running --no-headers 2>/dev/null | wc -l | tr -d ' ')
if [ "$failed_pods" -gt 0 ]; then
    echo "  ‚ö†Ô∏è Pods en erreur: $failed_pods"
else
    echo "  ‚úì Aucun pod en erreur d√©tect√©"
fi

# 2. Afficher les leases d√©truits (si backup disponible)
echo ""
if [ -f "$BACKUP_FILE" ]; then
    echo "2. Leases d√©truits (selon backup: $BACKUP_FILE):"
    total_leases=$(jq '. | length' "$BACKUP_FILE" 2>/dev/null || echo "0")
    echo "  Total de leases dans le backup: $total_leases"
    
    orphan_leases=$(jq '[.[] | select(.orphan == true)] | length' "$BACKUP_FILE" 2>/dev/null || echo "0")
    echo "  Leases orphelins dans le backup: $orphan_leases"
    
    echo ""
    echo "  Premiers leases d√©truits:"
    jq -r '.[] | "    - \(.full_path) (orphan: \(.orphan // false))"' "$BACKUP_FILE" | head -10
    echo "    ... (voir $BACKUP_FILE pour la liste compl√®te)"
else
    echo "2. ‚ö†Ô∏è Aucun fichier backup trouv√©: $BACKUP_FILE"
    echo "   Recherche de fichiers backup..."
    ls -t leases.json.backup* 2>/dev/null | head -1 | while read backup; do
        echo "   Fichier trouv√©: $backup"
        echo "   Utilisez: $0 $NAMESPACE $backup"
    done || echo "   Aucun fichier backup trouv√©"
fi

# 3. Proposer la r√©cup√©ration
echo ""
echo "3. Proc√©dure de r√©cup√©ration propos√©e:"
echo ""
echo "   a) Red√©marrer les deployments (RECOMMAND√â):"
echo "      kubectl rollout restart deployment -n $NAMESPACE"
echo ""
echo "   b) OU supprimer les pods:"
echo "      kubectl delete pods -n $NAMESPACE --all"
echo ""
echo "   c) V√©rifier le statut:"
echo "      kubectl get pods -n $NAMESPACE"
echo "      kubectl rollout status deployment -n $NAMESPACE"
echo ""
echo "4. Apr√®s r√©cup√©ration, v√©rifier les nouveaux leases:"
if [ -n "$VAULT_ADDR" ]; then
    echo "   export VAULT_ADDR=\"$VAULT_ADDR\""
fi
echo "   export LEASE_LIST_PATHS=\"<path-du-namespace>\""
echo "   ./scripts/list-lease.sh"
echo ""
echo "=========================================="
echo "‚ö†Ô∏è Voulez-vous proc√©der √† la r√©cup√©ration ?"
echo "=========================================="
echo ""
read -p "Red√©marrer les deployments du namespace $NAMESPACE ? (yes/no): " confirm

if [ "$confirm" = "yes" ]; then
    echo ""
    echo "Red√©marrage des deployments..."
    kubectl rollout restart deployment -n "$NAMESPACE"
    
    echo ""
    echo "Attente du red√©ploiement (timeout: 5 minutes)..."
    kubectl rollout status deployment -n "$NAMESPACE" --timeout=300s
    
    echo ""
    echo "‚úì R√©cup√©ration termin√©e"
    echo ""
    echo "V√©rifiez maintenant que les pods sont Running:"
    echo "  kubectl get pods -n $NAMESPACE"
else
    echo ""
    echo "R√©cup√©ration annul√©e. Ex√©cutez manuellement les commandes ci-dessus."
fi
```

**Sauvegarder ce script dans** `scripts/recover-leases.sh` et le rendre ex√©cutable :

```bash
chmod +x scripts/recover-leases.sh
```

## Checklist de R√©cup√©ration

Utilisez cette checklist apr√®s une suppression accidentelle :

### Phase 1 : √âvaluation Initiale
- [ ] ‚úÖ Identifier les pods/namespaces affect√©s
- [ ] ‚úÖ V√©rifier si un fichier `leases.json.backup` existe
- [ ] ‚úÖ Documenter quels leases ont √©t√© supprim√©s (si backup disponible)
- [ ] ‚úÖ √âvaluer l'impact sur les applications (quels services sont affect√©s)
- [ ] ‚úÖ V√©rifier l'√©tat des deployments/statefulsets

### Phase 2 : Pr√©paration
- [ ] ‚úÖ Informer les √©quipes concern√©es
- [ ] ‚úÖ Arr√™ter temporairement les d√©ploiements automatiques (si n√©cessaire)
- [ ] ‚úÖ Pr√©parer les commandes de r√©cup√©ration
- [ ] ‚úÖ V√©rifier l'acc√®s √† Vault et Kubernetes

### Phase 3 : R√©cup√©ration
- [ ] ‚úÖ Red√©marrer les pods (via rollout restart ou delete)
- [ ] ‚úÖ Surveiller le red√©ploiement
- [ ] ‚úÖ V√©rifier que les nouveaux pods d√©marrent correctement
- [ ] ‚úÖ V√©rifier que de nouveaux leases sont g√©n√©r√©s dans Vault
- [ ] ‚úÖ Tester le fonctionnement des applications

### Phase 4 : V√©rification
- [ ] ‚úÖ V√©rifier les logs des applications pour confirmer l'acc√®s aux secrets
- [ ] ‚úÖ Tester les fonctionnalit√©s critiques (acc√®s DB, API externes, etc.)
- [ ] ‚úÖ V√©rifier les pipelines CI/CD (relancer si n√©cessaire)
- [ ] ‚úÖ Comparer les nombres de leases avant/apr√®s (si backup disponible)

### Phase 5 : Post-Mortem
- [ ] ‚úÖ Documenter l'incident et les actions de r√©cup√©ration
- [ ] ‚úÖ Identifier la cause de l'erreur
- [ ] ‚úÖ Mettre en place des mesures pr√©ventives
- [ ] ‚úÖ Am√©liorer les proc√©dures de sauvegarde si n√©cessaire

## Pr√©vention Future

Pour √©viter ce type d'incident :

### 1. Toujours utiliser `DESTROY_ORPHANS_ONLY=true`

```yaml
# Dans gitlab-ci.yaml
variables:
  DESTROY_ORPHANS_ONLY: "true"  # Ne d√©truire QUE les orphelins
```

### 2. Sauvegarder syst√©matiquement `leases.json` avant destruction

Modifier le script `destroy-lease.sh` pour cr√©er automatiquement une sauvegarde :

```bash
# √Ä ajouter au d√©but de destroy-lease.sh
if [ -f "$INPUT_FILE" ]; then
    BACKUP_FILE="${INPUT_FILE}.backup-$(date +%Y%m%d-%H%M%S)"
    echo "Cr√©ation d'une sauvegarde: $BACKUP_FILE"
    cp "$INPUT_FILE" "$BACKUP_FILE"
    echo "Sauvegarde cr√©√©e: $BACKUP_FILE"
fi
```

### 3. Utiliser la destruction manuelle (`when: manual`)

Dans `gitlab-ci.yaml` :
```yaml
destroy_vault_leases:
  when: manual  # N√©cessite une confirmation manuelle
```

### 4. Valider la liste des leases avant destruction

Cr√©er un stage de validation dans la pipeline :
```yaml
validate_leases_before_destroy:
  stage: validate
  script:
    - |
      echo "V√©rification des leases √† d√©truire..."
      total=$(jq '. | length' "$OUTPUT_FILE")
      orphans=$(jq '[.[] | select(.orphan == true)] | length' "$OUTPUT_FILE")
      echo "Total: $total, Orphelins: $orphans"
      if [ "$total" -gt 100 ]; then
        echo "‚ö†Ô∏è ATTENTION: Plus de 100 leases √† d√©truire!"
        exit 1
      fi
  when: manual
```

### 5. Tester sur un environnement non-critique d'abord

- Toujours tester sur `dev` ou `int` avant d'appliquer sur `prod`
- Utiliser un namespace de test pour valider la proc√©dure

### 6. Impl√©menter un m√©canisme de backup automatique

Dans GitLab CI, ajouter un job qui archive le fichier JSON :
```yaml
archive_leases_backup:
  stage: list_leases
  script:
    - |
      BACKUP_FILE="leases-backup-$(date +%Y%m%d-%H%M%S).json"
      cp "$OUTPUT_FILE" "$BACKUP_FILE"
      echo "Sauvegarde cr√©√©e: $BACKUP_FILE"
  artifacts:
    paths:
      - "leases-backup-*.json"
    expire_in: 30 days
```

## Contacts et Escalade

En cas de probl√®me majeur :

1. **Administrateur Vault** : Pour les questions sur les secrets et leases
2. **Administrateur Kubernetes** : Pour les probl√®mes de red√©marrage des pods
3. **√âquipe DevOps/SRE** : Pour l'aide √† la r√©cup√©ration
4. **√âquipe Applicative** : Pour valider le fonctionnement des applications apr√®s r√©cup√©ration

## Ressources Utiles

- [Documentation Vault - Leases](https://www.vaultproject.io/docs/concepts/lease)
- [Documentation Kubernetes - Troubleshooting Pods](https://kubernetes.io/docs/tasks/debug/debug-application/debug-running-pod/)
- [GitLab CI/CD - Pipeline Recovery](https://docs.gitlab.com/ee/ci/pipelines/index.html)

